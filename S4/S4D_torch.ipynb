{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2034c9c3ed4ef68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:05:08.880732Z",
     "start_time": "2024-09-13T15:05:08.649896Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tristan/miniconda3/envs/.jax_conda_env_MML_2/bin/python\r\n",
      "/home/tristan/ModernML/S4\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62877a9e33e7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Random SSM\n",
    "This notebook trains a Random SSM on sin(x) or sin(ax+b) sequences. \n",
    "The hyperparameters are defined in the `config.yaml` file. \n",
    "- N (hidden state dimension): 64\n",
    "- H (d_model in yaml, number of heads): 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f398bd97bb211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:15:58.439472Z",
     "start_time": "2024-09-13T15:15:56.528373Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from data import Datasets\n",
    "from model import BatchStackedModel, MultiHeadSSMLayer, MultiHeadS4DLayer\n",
    "import torch\n",
    "import torchsummary\n",
    "from utils import cross_entropy_loss, compute_accuracy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os \n",
    "# set device to \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#check if cuda is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4050a5fc7f3756d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:15:59.127910Z",
     "start_time": "2024-09-13T15:15:58.440546Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8eb0bee5f15fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:15:59.152849Z",
     "start_time": "2024-09-13T15:15:59.129380Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load the configuration file\n",
    "cfg = OmegaConf.load(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6a6cc3f5962942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:15:59.156146Z",
     "start_time": "2024-09-13T15:15:59.153860Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = cfg.dataset  # str, sin_ax, sin_ax_b\n",
    "layer = cfg.layer  # str, s4\n",
    "seed  = cfg.seed  # int, 0\n",
    "model_p = cfg.model  # DictConfig, {d_model: 10 (nb heads), n_layers: 4, dropout: 0.0, prenorm: true, embedding: false, layer: {N:64}}\n",
    "train_p = cfg.train  # DictConfig, {epochs: 100, bsz: 128, lr: 0.001, lr_schedule: false, weight_decay: 0.01, checkpoint: false, suffix: null, sample: null}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486b29a5e500b300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:15:59.253486Z",
     "start_time": "2024-09-13T15:15:59.157760Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Setting Randomness...\n"
     ]
    }
   ],
   "source": [
    "# Set randomness...\n",
    "print(\"[*] Setting Randomness...\")\n",
    "torch.random.manual_seed(seed)  # For dataloader order\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, rng, train_rng = jax.random.split(key, num=3) # TODO: This is bad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b4b38b22ba9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.350188Z",
     "start_time": "2024-09-13T15:15:59.254647Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification=True\n",
      "[*] Generating CIFAR-10 Classification Dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "n_classes=10, l_max=1024, d_input=1\n",
      "next(iter(trainloader))[0].shape=torch.Size([64, 1024, 1])\n",
      "next(iter(testloader))[0].shape=torch.Size([64, 1024, 1])\n"
     ]
    }
   ],
   "source": [
    "# Check if classification dataset\n",
    "# because for each dataset there are two versions, eg: mnist and mnist-classification\n",
    "dataset = 'cifar-gs-classification'\n",
    "classification = \"classification\" in dataset\n",
    "print(f'{classification=}')\n",
    "\n",
    "create_dataset_fn = Datasets[dataset]\n",
    "# trainloader, testloader, n_classes, l_max, d_input, data = create_dataset_fn(n_examples=1024, bsz=train.bsz)\n",
    "trainloader, testloader, n_classes, l_max, d_input = create_dataset_fn(bsz=train_p.bsz)\n",
    "print(f'{n_classes=}, {l_max=}, {d_input=}')\n",
    "\n",
    "print(f'{next(iter(trainloader))[0].shape=}')\n",
    "print(f'{next(iter(testloader))[0].shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44894e1adcfb090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.355220Z",
     "start_time": "2024-09-13T15:16:00.351430Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model_torch import S4Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75029c494dd1c489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.415239Z",
     "start_time": "2024-09-13T15:16:00.355899Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = S4Model(\n",
    "    d_input=d_input,\n",
    "    d_output=n_classes,\n",
    "    d_model=model_p.d_model,\n",
    "    d_state=model_p.layer.N,\n",
    "    lr=train_p.lr,\n",
    "    dropout=model_p.dropout,\n",
    "    \n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c109cdbbefb770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.418535Z",
     "start_time": "2024-09-13T15:16:00.416018Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S4Model(\n",
      "  (encoder): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (s4_layers): ModuleList(\n",
      "    (0-3): 4 x S4D(\n",
      "      (kernel): S4DKernel()\n",
      "      (activation): GELU(approximate='none')\n",
      "      (dropout): DropoutNd()\n",
      "      (output_linear): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "        (1): GLU(dim=-2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-3): 4 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (dropouts): ModuleList(\n",
      "    (0-3): 4 x Dropout1d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3140c3c06029c947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.428908Z",
     "start_time": "2024-09-13T15:16:00.420144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# torchsummary.summary(model, (1,1,2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23903e6508bfd420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.440965Z",
     "start_time": "2024-09-13T15:16:00.429638Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# # define a adam optimizer\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=train_p.lr, weight_decay=train_p.weight_decay)\n",
    "# #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=train_p.epochs)\n",
    "# \n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.2)\n",
    "# # define weight decay\n",
    "# \n",
    "# # define a loss function\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define device of apple \"mps\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device=}')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142c744df9ab87c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.452225Z",
     "start_time": "2024-09-13T15:16:00.441668Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer group 0 | 28 tensors | lr 0.01 | weight_decay 0.01\n",
      "Optimizer group 1 | 12 tensors | lr 0.001 | weight_decay 0.0\n"
     ]
    }
   ],
   "source": [
    "def setup_optimizer(model, lr, weight_decay, epochs):\n",
    "    \"\"\"\n",
    "    S4 requires a specific optimizer setup.\n",
    "\n",
    "    The S4 layer (A, B, C, dt) parameters typically\n",
    "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
    "\n",
    "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
    "    and weight decay (if desired).\n",
    "    \"\"\"\n",
    "\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts\n",
    "    for hp in hps:\n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp]\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    # Print optimizer info\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer, scheduler = setup_optimizer(\n",
    "    model, lr=train_p.lr, weight_decay=train_p.weight_decay, epochs=train_p.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c57e58291e0961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.467751Z",
     "start_time": "2024-09-13T15:16:00.452992Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 32])\n",
      "torch.Size([128, 32])\n"
     ]
    }
   ],
   "source": [
    "for param in optimizer.param_groups[1]['params']:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4ca4d5c9f21990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:00.692749Z",
     "start_time": "2024-09-13T15:16:00.690103Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "            (batch_idx, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b471d6b5ff92cafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T15:16:01.235437Z",
     "start_time": "2024-09-13T15:16:01.231799Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(epoch, dataloader, checkpoint=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(dataloader))\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                (batch_idx, len(dataloader), eval_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "            )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if checkpoint:\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486184d6377b5bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(train_p.epochs):\n",
    "    if epoch == 0:\n",
    "        print(f\"Epoch | Train Loss | Train Acc | Test Loss | Test Acc\")\n",
    "        print(f\"-------------------------------------------------------\")\n",
    "    train()\n",
    "    val_acc = eval(epoch, testloader, checkpoint=False)\n",
    "    eval(epoch, testloader)\n",
    "    scheduler.step(val_acc)\n",
    "    print(f'{epoch=}, {val_acc=}, {scheduler.get_last_lr()}')\n",
    "    # print(f\"Epoch {epoch} learning rate: {scheduler.get_last_lr()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b52cec5f1959c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "id": "83546c66ea2a15e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
